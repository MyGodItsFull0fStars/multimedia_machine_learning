{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from time import perf_counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from models import CNNSmall, CNNModerate, VGG, VGG_11, VGG_16\n",
    "\n",
    "from utils import get_torch_device, get_torch_device_as_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH: str = './data'\n",
    "NUM_WORKERS_DATALOADER: int = 4\n",
    "\n",
    "BATCH_SIZE: int = 64\n",
    "LEARNING_RATE: float = 0.001\n",
    "MOMENTUM: float = 0.9\n",
    "\n",
    "NUM_EPOCHS: int = 3\n",
    "\n",
    "DEVICE = get_torch_device(include_mps=False)\n",
    "\n",
    "INCLUDE_WANDB: bool = True\n",
    "\n",
    "SMALL_DATASET: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INCLUDE_WANDB:\n",
    "    import wandb\n",
    "    config_dict = {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'num_epochs': NUM_EPOCHS,\n",
    "        'training_device': get_torch_device_as_string(),\n",
    "        'num_workers_dataloader': NUM_WORKERS_DATALOADER,\n",
    "        'dataset_size': 'small' if SMALL_DATASET else 'all',\n",
    "        'model type': 'CNN Small'\n",
    "    }\n",
    "    wandb.init(project='CNN', name='test', config=config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNSmall().to(DEVICE)\n",
    "# model = CNNModerate().to(DEVICE)\n",
    "# model = VGG(VGG_11).to(DEVICE)\n",
    "# model = VGG(VGG_16).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_classes: List[str] = ['plane', 'car', 'bird', 'cat',\n",
    "                            'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "transform_images = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=True, download=True, transform=transform_images)\n",
    "validation_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=True, download=True, transform=transform_images)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=False, download=True, transform=transform_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SMALL_DATASET:\n",
    "    train_dataset.data = train_dataset.data[:1000]\n",
    "    validation_dataset.data = validation_dataset.data[1000:2000]\n",
    "    test_dataset.data = test_dataset.data[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split: int = round(len(train_dataset) * 0.8)\n",
    "\n",
    "train_dataset.data = train_dataset.data[:validation_split]\n",
    "validation_dataset.data = validation_dataset.data[validation_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS_DATALOADER)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS_DATALOADER\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS_DATALOADER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(data_loader: DataLoader, is_validation: bool = False):\n",
    "    correct: int = 0\n",
    "    total: int = 0\n",
    "    validation_string: str = 'validation' if is_validation else 'test'\n",
    "\n",
    "    # prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in image_classes}\n",
    "    total_pred = {classname: 0 for classname in image_classes}\n",
    "\n",
    "    total_execution_time = perf_counter()\n",
    "\n",
    "    # the gradients don't get calculated while testing\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in tqdm(data_loader, desc=f'{validation_string} loop'):\n",
    "            batch_execution_time = perf_counter()\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            # calculate outputs by running images through the network\n",
    "            y_predictions = model(images)\n",
    "            # the class with the highest probability (energy) is what we choose as prediction\n",
    "            _, predicted = torch.max(y_predictions, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predicted):\n",
    "                if label == prediction:\n",
    "                    correct_pred[image_classes[label]] += 1\n",
    "                total_pred[image_classes[label]] += 1\n",
    "\n",
    "            if INCLUDE_WANDB:\n",
    "                wandb.log(\n",
    "                    {f'{validation_string} batch execution time': perf_counter() - batch_execution_time})\n",
    "\n",
    "    accuracy = round(100 * correct / total, 4)\n",
    "    if not is_validation:\n",
    "        print(\n",
    "            f'Accuracy of the network on the {len(data_loader.dataset)} test images: {accuracy} %')\n",
    "\n",
    "    if INCLUDE_WANDB:\n",
    "        if is_validation:\n",
    "            wandb.log({\n",
    "                f'{validation_string} accuracy': accuracy,\n",
    "                f'{validation_string} total execution time': perf_counter() - total_execution_time\n",
    "            })\n",
    "        wandb.run.summary[f'{validation_string} dataset overall accuracy %'] = accuracy\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = round(100 * correct_count / total_pred[classname], 4)\n",
    "        if not is_validation:\n",
    "            print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "        if INCLUDE_WANDB:\n",
    "            key = f'{validation_string} {classname} accuracy'\n",
    "            wandb.log({\n",
    "                key: accuracy\n",
    "            })\n",
    "            wandb.run.summary[key] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training_time = perf_counter()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    correct_predictions: int = 0\n",
    "    total_predictions: int = 0\n",
    "    \n",
    "    training_loop_execution_time = perf_counter()\n",
    "    for idx, (inputs, labels) in enumerate(tqdm(train_dataloader, desc='train loop'), 0):\n",
    "        batch_execution_time = perf_counter()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        # forward pass\n",
    "        y_hat = model(inputs)\n",
    "        \n",
    "        # calculate losses\n",
    "        loss = loss_function(y_hat, labels)\n",
    "        # backpropagate the new gradients\n",
    "        loss.backward()\n",
    "        # optimize the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, y_predictions = torch.max(y_hat, 1)\n",
    "        correct_predictions += torch.sum(y_predictions == labels).item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        if INCLUDE_WANDB:\n",
    "            wandb.log({'batch execution time': perf_counter() - batch_execution_time})\n",
    "        \n",
    "    if INCLUDE_WANDB:\n",
    "        training_loop_execution_time = perf_counter() - training_loop_execution_time\n",
    "        train_accuracy = 100 * correct_predictions / total_predictions\n",
    "        wandb.log({\n",
    "            'loss': loss.item(), \n",
    "            'training accuracy in %': train_accuracy,\n",
    "            'epoch execution time': training_loop_execution_time,\n",
    "            })\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    get_test_accuracy(validation_dataloader, is_validation=True)\n",
    "    # get_test_accuracy_of_each_class(validation_dataloader, is_validation=True)\n",
    "    model.train()\n",
    "    \n",
    "if INCLUDE_WANDB:\n",
    "    wandb.summary['total training time'] = round(perf_counter() - total_training_time, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH: str = f'./models/cifar_net.pth'\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_accuracy(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc289c9585466324d6bcd715c701435d361dd4760f0e3d7325b29a75549769c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
